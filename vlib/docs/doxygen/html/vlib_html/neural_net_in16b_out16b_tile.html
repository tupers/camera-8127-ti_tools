<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><meta http-equiv="Content-Type" content="text/html;charset=iso-8859-1">
<title>VLIB: Neural Net or Fully Connected Layer</title>
<link href="doxygen.css" rel="stylesheet" type="text/css">
<link href="tabs.css" rel="stylesheet" type="text/css">
</head><body>
<table width=100%>
<tr>
  <td bgcolor="black" width="1"><a href="http://www.ti.com"><img border=0 src="tilogo.gif"></a></td>
  <td bgcolor="red"><img src="titagline.gif"></td>
</tr>
</table>
<!-- Generated by Doxygen 1.5.1-p1 -->
<div class="tabs">
  <ul>
    <li><a href="index.html"><span>Main&nbsp;Page</span></a></li>
    <li><a href="modules.html"><span>Modules</span></a></li>
    <li><a href="annotated.html"><span>Data&nbsp;Structures</span></a></li>
    <li><a href="files.html"><span>Files</span></a></li>
  </ul></div>
<div class="nav">
<a class="el" href="index.html">VLIB Function Reference</a></div>
<h1><a class="anchor" name="neural_net_in16b_out16b_tile">Neural Net or Fully Connected Layer</a></h1><h2><a class="anchor" name="intro55">
Introduction</a></h2>
Fully Connected Layer operations are major part of CNN bulding blocks.<br>
 <br>
 Supports fully connected layer operations on 16-bit input nodes, keeping output range in 16-bit and activation functions such as ReLU, Sigmoid, Tanh on output nodes based on user defined mode. <br>
 <div class="fragment"><pre class="fragment">
    Data usage example (rows x columns):
                Input           :         M x N
                Weight          :         L x N
                Output          :         M x L
    </pre></div><h2><a class="anchor" name="specification55">
Specification</a></h2>
<h3><a class="anchor" name="function55">
Function</a></h3>
Input nodes of 16-bit values are transformed to output nodes with fully connected layer operations. It is then biased, rounded and shifted down to fit in signed 16-bit range. Shift value is calculated as sum of user defined shift value and dropout value. Activation functions such as ReLU, Sigmoid, Tanh are performed on output nodes based on user defined mode, prior to storing in the output array.<h3><a class="anchor" name="apis55">
API</a></h3>
<ul>
<li>VLIB_neuralNet_tile </li></ul>
<hr size="1"><small>
Copyright  2016, Texas Instruments Incorporated</small>
</body>
</html>
